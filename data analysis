import pandas as pd
from collections import Counter
import re

# === Step 1: Load review data from Sheet1 ===
file_path = 'production reviews .xlsx'  # Make sure the filename and path are correct
df = pd.read_excel(file_path, sheet_name='Sheet1')

# === Step 2: Define keyword extraction function for brand personality ===
def extract_brand_personality_words(text):
    if not text or not isinstance(text, str):
        return []
    
    keywords = []

    # Dimension: Quality & Trustworthiness
    quality_terms = ['大品牌', '品牌', '值得信赖', '值得', '可靠', '信赖', '经典', '传统', '专业', '权威', '正品']
    
    # Dimension: Functional Effectiveness
    effect_terms = ['保湿', '滋润', '紧致', '提亮', '修护', '淡化', '改善', '有效', '明显', '神奇', '好用', '实用']
    
    # Dimension: Sensory & Aesthetic Experience
    experience_terms = ['舒适', '温和', '清爽', '不刺激', '吸收', '质地', '包装', '精美', '漂亮', '高端', '奢华']
    
    # Dimension: Emotional Satisfaction & Loyalty
    emotion_terms = ['喜欢', '满意', '推荐', '惊喜', '心动', '回购', '种草', '爱用', '无限回购']
    
    # Dimension: Price & Perceived Value
    value_terms = ['划算', '性价比', '超值', '物美价廉', '便宜', '贵', '物超所值']

    # Append any matched term to keyword list
    for term_list in [quality_terms, effect_terms, experience_terms, emotion_terms, value_terms]:
        for term in term_list:
            if term in text:
                keywords.append(term)

    # General evaluative expressions via regex
    general_pattern = r'可以|还行'
    general_terms = re.findall(general_pattern, text)
    keywords.extend(general_terms)

    return keywords

# === Step 3: Analyze each brand's reviews ===
brand_analysis_results = {}
brands = df['品牌'].unique()  # Unique brand names from the dataset

for brand_name in brands:
    brand_data = df[df['品牌'] == brand_name]
    all_words = []
    valid_count = 0

    for _, row in brand_data.iterrows():
        comment = row.get('初评')
        if pd.notna(comment) and isinstance(comment, str) and len(comment) > 5:
            valid_count += 1
            words = extract_brand_personality_words(comment)
            all_words.extend(words)

    # Count frequency of each keyword
    word_freq = Counter(all_words)
    # Keep top 15 keywords that appear ≥ 5 times
    sorted_words = [(word, count) for word, count in word_freq.most_common() if count >= 5][:15]

    brand_analysis_results[brand_name] = {
        'total_reviews': len(brand_data),
        'valid_reviews': valid_count,
        'total_words': len(all_words),
        'top_words': sorted_words
    }

# === Step 4: Print brand-specific results ===
print("=== Brand Personality Analysis ===\n")
for brand_name, res in brand_analysis_results.items():
    print(f"【{brand_name}】")
    print(f"Valid Reviews: {res['valid_reviews']} / {res['total_reviews']}")
    print("Top Keywords (occurrence ≥ 5):")
    if res['top_words']:
        for i, (word, count) in enumerate(res['top_words'], 1):
            print(f"  {i}. {word} ({count} times)")
    else:
        print("  No significant keywords found.")
    print()

# === Step 5: Cross-brand comparison for "好用" (easy-to-use) ===
print("=== Frequency of '好用' Across Brands ===")
good_usage = []
for brand_name, res in brand_analysis_results.items():
    count = next((count for word, count in res['top_words'] if word == '好用'), 0)
    good_usage.append((brand_name, count))

good_usage.sort(key=lambda x: x[1], reverse=True)
for brand_name, count in good_usage:
    print(f"{brand_name}: {count} times")

# === Step 6: Most dominant keyword (Top 1) for each brand ===
print("\n=== Top-1 Keyword for Each Brand ===")
top_features = []
for brand_name, res in brand_analysis_results.items():
    if res['top_words']:
        word, count = res['top_words'][0]
        top_features.append((brand_name, word, count))

top_features.sort(key=lambda x: x[2], reverse=True)
for brand, word, count in top_features:
    print(f"{brand}: {word} ({count} times)")

# Define trust-related keyword categories
trust_keywords = {
    'direct_trust': ['信任', '放心', '可靠', '信赖', '靠谱', '安心', '相信'],
    'repeat_purchase': ['回购', '再买', '继续买', '一直买', '无限回购', '持续回购'],
    'recommendation': ['推荐', '安利', '种草', '值得买', '建议', '介绍'],
    'quality_confidence': ['大品牌', '品牌', '正品', '值得', '品质', '质量好'],
    'effect_confidence': ['有效', '管用', '见效', '效果好', '明显', '确实好用']
}

# Function to compute trust metrics for a single brand DataFrame
def calculate_trust_metrics(df, brand_name):
    trust_scores = {
        'direct_trust': 0,
        'repeat_purchase': 0,
        'recommendation': 0,
        'quality_confidence': 0,
        'effect_confidence': 0,
        'total_reviews': 0,
        'valid_reviews': 0
    }

    for review in df['初评'].dropna():
        if isinstance(review, str):
            trust_scores['total_reviews'] += 1
            has_any_trust = False

            # Check if any trust-related keyword is present in the review
            for category, keywords in trust_keywords.items():
                for keyword in keywords:
                    if keyword in review:
                        trust_scores[category] += 1
                        has_any_trust = True

            if has_any_trust:
                trust_scores['valid_reviews'] += 1

    # Normalize score to compute a composite trust index
    max_possible = trust_scores['total_reviews'] * 5  # 5 trust dimensions
    actual_trust = sum(trust_scores[k] for k in trust_keywords.keys())
    trust_scores['trust_index'] = round((actual_trust / max_possible * 100), 2) if max_possible > 0 else 0

    return trust_scores

# Main function to analyze trust scores in df
def analyze_trust_from_dataframe(df):
    results = {}
    brands = df['品牌'].unique()

    for brand in brands:
        print(f"\n【{brand} - Trust Analysis】")

        brand_df = df[df['品牌'] == brand]
        trust_metrics = calculate_trust_metrics(brand_df, brand)
        results[brand] = trust_metrics
        # trust_results = analyze_trust_from_dataframe(df)


        print(f"Total Reviews: {trust_metrics['total_reviews']}")
        print()
        print(f"Trust-Related Reviews: {trust_metrics['valid_reviews']} "
              f"({trust_metrics['valid_reviews']/trust_metrics['total_reviews']*100:.1f}%)")
        print("Breakdown by Trust Dimensions:")
        print(f"  Direct Trust: {trust_metrics['direct_trust']} mentions")
        print(f"  Repeat Purchase: {trust_metrics['repeat_purchase']} mentions")
        print(f"  Recommendation: {trust_metrics['recommendation']} mentions")
        print(f"  Quality Confidence: {trust_metrics['quality_confidence']} mentions")
        print(f"  Effectiveness Confidence: {trust_metrics['effect_confidence']} mentions")
        print(f"Composite Trust Index: {trust_metrics['trust_index']} / 100")

    return results
if __name__ == "__main__":
    trust_results = analyze_trust_from_dataframe(df)

import pandas as pd
from collections import defaultdict

# Define brand image keyword dictionary
brand_image_keywords = {
    '实用功效': ['好用', '实用', '有效', '管用', '见效', '改善', '紧致', '提亮', '修护', '淡化', '保湿', '滋润'],
    '品质感知': ['大品牌', '品质', '质量好', '正品', '专业', '经典', '权威', '可靠', '信赖', '放心'],
    '品牌声誉': ['品牌', '有名', '知名', '口碑好', '老牌', '高端', '大厂', '值得'],
    '审美体验': ['包装', '精美', '漂亮', '高级', '质地', '高端', '奢华', '香味好闻', '外观好看', '触感细腻'],
    '情感连接': ['喜欢', '满意', '心动', '惊喜', '无限回购', '爱用', '信任感强', '情怀', '情感连接', '陪伴感']
}

# Function to count brand image dimensions and return DataFrame
def count_brand_image_keywords(df):
    """
    Count keyword mentions for each brand across 5 image dimensions.
    Returns a pandas DataFrame.
    """
    results = {}

    for brand in df['品牌'].unique():
        brand_df = df[df['品牌'] == brand]
        keyword_counts = defaultdict(int)

        for review in brand_df['初评'].dropna():
            if isinstance(review, str):
                for category, keywords in brand_image_keywords.items():
                    for kw in keywords:
                        if kw in review:
                            keyword_counts[category] += 1

        results[brand] = dict(keyword_counts)

    # Convert to DataFrame
    result_df = pd.DataFrame.from_dict(results, orient='index')
    result_df.fillna(0, inplace=True)
    result_df = result_df.astype(int)
    return result_df

image_df = count_brand_image_keywords(df)
print(image_df)


import pandas as pd
import math

# Define brand image and trust keywords
brand_image_keywords = {
    '实用功效': ['好用', '实用', '有效', '管用', '见效', '改善', '紧致', '提亮', '修护', '淡化', '保湿', '滋润'],
    '品质感知': ['大品牌', '品质', '质量好', '正品', '专业', '经典', '权威', '可靠', '信赖', '放心'],
    '品牌声誉': ['品牌', '有名', '知名', '口碑好', '老牌', '高端', '大厂', '值得'],
    '审美体验': ['包装', '精美', '漂亮', '高级', '质地', '高端', '奢华', '香味好闻', '外观好看', '触感细腻'],
    '情感连接': ['喜欢', '满意', '心动', '惊喜', '无限回购', '爱用', '信任感强', '情怀', '情感连接', '陪伴感']
}

trust_keywords = {
    'direct_trust': ['信任', '放心', '可靠', '信赖', '靠谱', '安心', '相信'],
    'repeat_purchase': ['回购', '再买', '继续买', '一直买', '无限回购', '持续回购'],
    'recommendation': ['推荐', '安利', '种草', '值得买', '建议', '介绍'],
    'quality_confidence': ['大品牌', '品牌', '正品', '值得', '品质', '质量好'],
    'effect_confidence': ['有效', '管用', '见效', '效果好', '明显', '确实好用']
}

# Functions
def count_brand_image_keywords(df):
    results = {}
    for brand in df['品牌'].unique():
        brand_df = df[df['品牌'] == brand]
        keyword_counts = {dim: 0 for dim in brand_image_keywords}
        for review in brand_df['初评'].dropna():
            for dim, keywords in brand_image_keywords.items():
                if any(kw in review for kw in keywords):
                    keyword_counts[dim] += 1
        results[brand] = keyword_counts
    return results

def calculate_trust_metrics(df):
    trust_scores = {k: 0 for k in trust_keywords}
    trust_scores.update({'total_reviews': 0, 'valid_reviews': 0})
    for review in df['初评'].dropna():
        if isinstance(review, str):
            trust_scores['total_reviews'] += 1
            has_any_trust = False
            for category, keywords in trust_keywords.items():
                if any(keyword in review for keyword in keywords):
                    trust_scores[category] += 1
                    has_any_trust = True
            if has_any_trust:
                trust_scores['valid_reviews'] += 1
    max_possible = trust_scores['total_reviews'] * 5
    actual_trust = sum(trust_scores[k] for k in trust_keywords)
    trust_scores['trust_index'] = round((actual_trust / max_possible * 100), 2) if max_possible > 0 else 0
    return trust_scores

def pearson_corr(x, y):
    n = len(x)
    mean_x = sum(x) / n
    mean_y = sum(y) / n
    dx = [i - mean_x for i in x]
    dy = [j - mean_y for j in y]
    numerator = sum(dx[i]*dy[i] for i in range(n))
    denominator = math.sqrt(sum(d**2 for d in dx) * sum(d**2 for d in dy))
    return round(numerator / denominator, 3) if denominator != 0 else 0

# Load data
file_path = "production reviews .xlsx"
df = pd.read_excel(file_path)

# Analyze data
trust_results = {brand: calculate_trust_metrics(group) for brand, group in df.groupby('品牌')}
brand_image_results = count_brand_image_keywords(df)

# Merge for analysis
analysis_data = []
for brand in trust_results:
    row = {
        'brand': brand,
        'trust_index': trust_results[brand]['trust_index']
    }
    row.update(brand_image_results.get(brand, {}))
    analysis_data.append(row)

df_analysis = pd.DataFrame(analysis_data)

# Correlation analysis
dimensions = ['实用功效', '品质感知', '品牌声誉', '审美体验', '情感连接']
trust_scores = df_analysis['trust_index'].tolist()

corr_results = []
for dim in dimensions:
    dim_scores = df_analysis[dim].tolist()
    corr = pearson_corr(dim_scores, trust_scores)
    abs_corr = abs(corr)
    if abs_corr >= 0.7:
        strength = '强相关'
    elif abs_corr >= 0.5:
        strength = '较强相关'
    elif abs_corr >= 0.3:
        strength = '中等相关'
    else:
        strength = '弱相关'
    corr_results.append((dim, corr, strength))

corr_results.sort(key=lambda x: abs(x[1]), reverse=True)

# Output correlation result
df_corr = pd.DataFrame(corr_results, columns=["Dimension", "Pearson_r", "Strength"])
df_corr

import pandas as pd
import re
from unidecode import unidecode  # If not installed: pip install Unidecode

def _brand_key(s: str) -> str:
    """Normalize brand name to a merge key: lowercase, strip spaces/punctuations, ASCII fold."""
    if pd.isna(s):
        return ""
    # ASCII fold (é -> e etc.), remove non-alphanumeric characters, convert to lowercase
    s_ascii = unidecode(str(s))
    s_ascii = re.sub(r"[^A-Za-z0-9]+", "", s_ascii).lower()
    return s_ascii

def merge_trust_with_image(df_trust_index: pd.DataFrame, image_df: pd.DataFrame) -> pd.DataFrame:
    # 1) Normalize trust index table
    trust = df_trust_index.copy()
    trust["__key__"] = trust["Brand"].apply(_brand_key)

    # 2) Normalize image table (reset index so brand name becomes a column)
    img = image_df.copy()
    img = img.reset_index().rename(columns={"index": "Brand_Image"})
    img["__key__"] = img["Brand_Image"].apply(_brand_key)

    # 3) Merge both tables on normalized key
    # Use "inner" to keep only matched brands (change to "outer" to keep all brands with NaN or 0)
    merged = pd.merge(trust, img, on="__key__", how="inner")

    # 4) Choose display name: prefer brand name from trust index table
    merged["Brand_Display"] = merged["Brand"]

    # 5) Reorder columns for readability
    cols_order = ["Brand_Display", "Trust_Index", "实用功效", "品质感知", "品牌声誉", "审美体验", "情感连接"]
    merged = merged.reindex(columns=cols_order)

    # 6) Sort by trust index (descending) and clean index
    merged = merged.sort_values(by="Trust_Index", ascending=False).reset_index(drop=True)
    merged = merged.rename(columns={"Brand_Display": "Brand"})

    return merged

summary_merged = merge_trust_with_image(df_trust_index, image_df)
print(summary_merged.to_string(index=False))

import pandas as pd

# Original nested dictionary
brand_data = {
    'SK-II': {'type': 'Luxury', 'trust_index': 7.27, 'price': 700},
    'LAMER': {'type': 'Luxury', 'trust_index': 3.67, 'price': 1110},
    'EsteeLauder': {'type': 'Luxury', 'trust_index':7.67, 'price': 515},
    'Lancome': {'type': 'Luxury', 'trust_index': 4.33, 'price': 20},
    'L\'Oreal': {'type': 'Mass Market', 'trust_index': 12.33, 'price': 259},
    'The Ordinary': {'type': 'Mass Market', 'trust_index': 3.73, 'price': 120},
    'nivea': {'type': 'Mass Market', 'trust_index': 4.67, 'price': 54},
    'Perfectdiary': {'type': 'Mass Market', 'trust_index': 3.73, 'price': 59}
}

# Convert into DataFrame
df2 = pd.DataFrame.from_dict(brand_data, orient='index').reset_index()
df2 = df2.rename(columns={'index': 'brand'})

print(df2)
import pandas as pd
import numpy as np
import re

# 1) Keyword dictionaries

value_keywords = {
    'functional_value': {
        'primary':   ['有效', '管用', '好用', '实用', '效果好'],
        'secondary': ['见效', '改善', '明显', '保湿', '滋润', '紧致', '提亮', '修护', '淡化']
    },
    'emotional_value': {
        'primary':   ['喜欢', '爱用', '心动', '惊喜', '满意'],
        'secondary': ['开心', '愉悦', '舒适', '温和', '清爽', '享受']
    },
    'social_value': {
        'primary':   ['大品牌', '知名', '有面子', '高端', '奢华'],
        'secondary': ['优雅', '精致', '品味', '档次', '身份']
    },
    'cognitive_value': {
        'primary':   ['划算', '值得', '性价比', '超值', '物美价廉'],
        'secondary': ['便宜', '实惠', '合理', '物超所值', '经济']
    }
}

price_fairness_keywords = {
    'price_acceptance':   {'primary': ['价格合理', '可以接受', '不贵', '价格合适', '值这个价'],
                           'secondary': ['价格OK', '价位合适', '接受这个价']},
    'price_sensitivity':  {'primary': ['太贵', '贵了', '价格高', '离谱', '不划算'],
                           'secondary': ['有点贵', '偏贵', '贵死', '贵爆']},
    'value_for_money':    {'primary': ['性价比', '划算', '超值', '物超所值', '值回票价'],
                           'secondary': ['便宜', '优惠', '活动价', '折扣多']},
    'price_comparison':   {'primary': ['比专柜便宜', '同款更便宜', '比XX贵', '对比价格'],
                           'secondary': ['价格对比', '比旗舰店便宜', '比实体店便宜']}
}

def valid_text(text: str, min_len: int = 6) -> bool:
    return isinstance(text, str) and len(text.strip()) >= min_len

def preprocess_text(text: str) -> str:
    """Light-weight preprocessing."""
    if not isinstance(text, str):
        return ""
    # normalize spaces and fullwidth punctuation a bit
    t = re.sub(r"\s+", "", text)
    return t

def count_dimension_keywords(review: str, kw_dict: dict) -> int:
    """
    Count total occurrences of primary + secondary keywords in review.
    """
    if not review:
        return 0
    total = 0
    for level in ('primary', 'secondary'):
        for kw in kw_dict.get(level, []):
            total += review.count(kw)
    return total


#Perceived Value

def analyze_perceived_value(review_df: pd.DataFrame, brand_name: str) -> dict:
    """
    Compute perceived value metrics for a single brand from a DataFrame
    that contains at least columns ['品牌', '初评'].
    """
    v = {
        'functional_value': 0,
        'emotional_value': 0,
        'social_value': 0,
        'cognitive_value': 0,
        'total_reviews': 0,
        'valid_reviews': 0
    }

    for _, row in review_df.iterrows():
        txt = row.get('初评')
        if isinstance(txt, str):
            v['total_reviews'] += 1
            if valid_text(txt, 6):
                has_any = False
                review = preprocess_text(txt)
                for cat, kws in value_keywords.items():
                    c = count_dimension_keywords(review, kws)
                    if c > 0:
                        v[cat] += c
                        has_any = True
                if has_any:
                    v['valid_reviews'] += 1

    total_mentions = sum(v[k] for k in ['functional_value','emotional_value','social_value','cognitive_value'])
    v['perceived_value_index'] = (total_mentions / v['total_reviews'] * 100) if v['total_reviews'] > 0 else 0.0
    return v


# 4) Price Fairness (by df)

def analyze_price_fairness(review_df: pd.DataFrame, brand_name: str, price: float) -> dict:
    """
    Compute price fairness metrics for a single brand from a DataFrame.
    `price` is included to keep signature consistent (not directly used in keyword counts).
    """
    f = {
        'price_acceptance': 0,
        'price_sensitivity': 0,
        'value_for_money': 0,
        'price_comparison': 0,
        'total_reviews': 0,
        'price_mentions': 0
    }

    for _, row in review_df.iterrows():
        txt = row.get('初评')
        if isinstance(txt, str):
            f['total_reviews'] += 1
            if valid_text(txt, 6):
                has_price = False
                review = preprocess_text(txt)
                for cat, kws in price_fairness_keywords.items():
                    c = count_dimension_keywords(review, kws)
                    if c > 0:
                        f[cat] += c
                        has_price = True
                if has_price:
                    f['price_mentions'] += 1

    net_accept = f['price_acceptance'] + f['value_for_money'] - f['price_sensitivity']
    f['price_fairness_index'] = (net_accept / f['price_mentions'] * 100) if f['price_mentions'] > 0 else 0.0
    return f


# 5) Orchestrator (df + df2)

def analyze_value_and_price_fairness_from_df(df_reviews: pd.DataFrame, df2_meta: pd.DataFrame):

    value_results = {}
    price_results = {}

    # Prepare a brand -> price dict from df2
    price_map = {row['brand']: row['price'] for _, row in df2_meta.iterrows()}

    # Iterate by brand in df_reviews
    for brand, g in df_reviews.groupby('品牌'):
        # perceived value
        value_results[brand] = analyze_perceived_value(g, brand)
        # price (lookup from df2; if not found -> NaN)
        price = price_map.get(brand, np.nan)
        price_results[brand] = analyze_price_fairness(g, brand, price)

    # Convert to DataFrames
    value_df = pd.DataFrame.from_dict(value_results, orient='index').reset_index().rename(columns={'index':'brand'})
    price_df = pd.DataFrame.from_dict(price_results, orient='index').reset_index().rename(columns={'index':'brand'})

    return value_df, price_df


value_df, price_df = analyze_value_and_price_fairness_from_df(df, df2)
print(value_df.head())
print(price_df.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
try:
    from unidecode import unidecode
except Exception:
    unidecode = None

plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


def _brand_key(s: str) -> str:
    """Normalize brand to a comparable key (ASCII fold -> remove non-alnum -> lower)."""
    if s is None or (isinstance(s, float) and np.isnan(s)):
        return ""
    text = str(s)
    if unidecode is not None:
        text = unidecode(text)
    text = re.sub(r"[^A-Za-z0-9]+", "", text).lower()
    return text


def _top_k_dims(d: dict, k=3):
    """Get top-k (dim, value) by value from a dict."""
    return sorted(d.items(), key=lambda x: x[1], reverse=True)[:k]


class TrustMechanismAnalyzer:
    """Analyzer for comparing trust-building mechanisms between luxury and mass-market brands (df-driven)."""

    def __init__(self, df2_meta: pd.DataFrame, image_df: pd.DataFrame, trust_results: dict):
        
      
        df2 = df2_meta.copy()
        if 'brand' not in df2.columns:
            raise ValueError("df2_meta must contain column 'brand'")
        df2['__key__'] = df2['brand'].apply(_brand_key)

        # image_df
        img = image_df.copy()
        img = img.reset_index().rename(columns={'index': 'brand_image'})
        img['__key__'] = img['brand_image'].apply(_brand_key)

        # trust_results：dict -> DataFrame
        tr_rows = []
        for b, metrics in trust_results.items():
            row = {'brand_trust': b, '__key__': _brand_key(b)}
            row.update(metrics)
            tr_rows.append(row)
        tr_df = pd.DataFrame(tr_rows) if tr_rows else pd.DataFrame(columns=['__key__'])

        # build brand_data
        self.brand_data = {}
        for _, r in df2.iterrows():
            self.brand_data[r['brand']] = {
                'type': r.get('type', ''),
                'trust_index': float(r.get('trust_index', 0.0)) if pd.notna(r.get('trust_index', np.nan)) else 0.0,
                'price': float(r.get('price', 0.0)) if pd.notna(r.get('price', np.nan)) else 0.0
            }

        # build brand_image_data
        # merged df2 to get image
        merged_img = pd.merge(df2[['brand','__key__']], img, on='__key__', how='left')
        self.brand_image_data = {}
        cn2en = {
            '实用功效': 'functional_effectiveness',
            '品质感知': 'quality_perception',
            '品牌声誉': 'brand_reputation',
            '审美体验': 'aesthetic_experience',
            '情感连接': 'emotional_connection'
        }
        for _, r in merged_img.iterrows():
            brand = r['brand']
            block = {}
            for cn, en in cn2en.items():
                val = r.get(cn, 0)
                if pd.isna(val):
                    val = 0
                block[en] = int(val) if isinstance(val, (int, np.integer)) else float(val)
            self.brand_image_data[brand] = block

        self.trust_components_data = {}

        if not tr_df.empty:
            merged_tr = pd.merge(df2[['brand','__key__']], tr_df, on='__key__', how='left')
            for _, r in merged_tr.iterrows():
                brand = r['brand']
                block = {
                    'direct_trust': int(r.get('direct_trust', 0) or 0),
                    'repeat_purchase': int(r.get('repeat_purchase', 0) or 0),
                    'recommendation': int(r.get('recommendation', 0) or 0),
                    'quality_confidence': int(r.get('quality_confidence', 0) or 0),
                    'effect_confidence': int(r.get('effect_confidence', 0) or 0),
                }
                self.trust_components_data[brand] = block
        else:
            for b in df2['brand']:
                self.trust_components_data[b] = {
                    'direct_trust': 0, 'repeat_purchase': 0, 'recommendation': 0,
                    'quality_confidence': 0, 'effect_confidence': 0
                }

        self.luxury_brands = [b for b, v in self.brand_data.items() if str(v.get('type','')).lower().startswith('lux')]
        self.mass_brands    = [b for b, v in self.brand_data.items() if str(v.get('type','')).lower().startswith('mass')]

        self.trust_dimension_names = {
            'direct_trust': 'Direct Trust Expression',
            'repeat_purchase': 'Repeat Purchase Intention',
            'recommendation': 'Recommendation Behavior',
            'quality_confidence': 'Quality Confidence',
            'effect_confidence': 'Effect Confidence'
        }
        self.image_dimension_names = {
            'functional_effectiveness': 'Functional Effectiveness',
            'quality_perception': 'Quality Perception',
            'brand_reputation': 'Brand Reputation',
            'aesthetic_experience': 'Aesthetic Experience',
            'emotional_connection': 'Emotional Connection'
        }

    def analyze_basic_comparison(self):
        print("GOAL 4: TRUST MECHANISM DIFFERENCES ANALYSIS ")
        print("\n4.1 Basic Comparison Analysis")

        luxury_trust = [self.brand_data[b]['trust_index'] for b in self.luxury_brands]
        mass_trust   = [self.brand_data[b]['trust_index'] for b in self.mass_brands]
        luxury_avg_trust = np.mean(luxury_trust) if luxury_trust else 0.0
        mass_avg_trust   = np.mean(mass_trust) if mass_trust else 0.0

        print("Trust Building Basic Metrics Comparison:")
        print(f"Luxury brands average trust: {luxury_avg_trust:.2f}%")
        print(f"Mass market brands average trust: {mass_avg_trust:.2f}%")
        diff = mass_avg_trust - luxury_avg_trust
        print(f"Difference: {diff:+.2f}% (Mass market brands {'higher' if diff>0 else 'lower'})")

        luxury_prices = [self.brand_data[b]['price'] for b in self.luxury_brands]
        mass_prices   = [self.brand_data[b]['price'] for b in self.mass_brands]
        luxury_avg_price = np.mean(luxury_prices) if luxury_prices else 0.0
        mass_avg_price   = np.mean(mass_prices) if mass_prices else 0.0

        print(f"\nPrice Level Comparison:")
        print(f"Luxury brands average price: ¥{luxury_avg_price:.0f}")
        print(f"Mass market brands average price: ¥{mass_avg_price:.0f}")
        if mass_avg_price > 0:
            print(f"Price multiple difference: {(luxury_avg_price / mass_avg_price):.1f}x")
        else:
            print("Price multiple difference: N/A")

        return {
            'luxury_avg_trust': luxury_avg_trust,
            'mass_avg_trust': mass_avg_trust,
            'luxury_avg_price': luxury_avg_price,
            'mass_avg_price': mass_avg_price
        }

    def analyze_trust_building_pathways(self):
        print("\n4.2 Trust Building Pathway Mechanism Analysis")
        dims = ['direct_trust', 'repeat_purchase', 'recommendation', 'quality_confidence', 'effect_confidence']
        print("Trust Building Pathway Comparison Analysis:")

        pathway_analysis = {}
        for d in dims:
            lux_vals = [self.trust_components_data[b][d] for b in self.luxury_brands if b in self.trust_components_data]
            mas_vals = [self.trust_components_data[b][d] for b in self.mass_brands if b in self.trust_components_data]
            lux_avg = np.mean(lux_vals) if lux_vals else 0.0
            mas_avg = np.mean(mas_vals) if mas_vals else 0.0
            difference = mas_avg - lux_avg

            pathway_analysis[d] = {'luxury_avg': lux_avg, 'mass_avg': mas_avg, 'difference': difference}

            print(f"{self.trust_dimension_names[d]}:")
            print(f"  Luxury brands: {lux_avg:.1f} times")
            print(f"  Mass market brands: {mas_avg:.1f} times")
            print(f"  Difference: {difference:+.1f} ({'Mass market advantage' if difference>0 else 'Luxury brand advantage'})")

        return pathway_analysis

    def analyze_brand_image_differences(self):
        print("\n4.3 Brand Image Dimension Difference Analysis")
        dims = list(self.image_dimension_names.keys())
        print("Brand Image Dimension Performance Comparison:")

        image_analysis = {}
        for d in dims:
            lux_vals = [self.brand_image_data[b][d] for b in self.luxury_brands if b in self.brand_image_data]
            mas_vals = [self.brand_image_data[b][d] for b in self.mass_brands if b in self.brand_image_data]
            lux_avg = np.mean(lux_vals) if lux_vals else 0.0
            mas_avg = np.mean(mas_vals) if mas_vals else 0.0
            difference = lux_avg - mas_avg
            image_analysis[d] = {'luxury_avg': lux_avg, 'mass_avg': mas_avg, 'difference': difference}

            significance = "Significant difference" if abs(difference) > 10 else "Minor difference"
            print(f"{self.image_dimension_names[d]}:")
            print(f"  Luxury brands: {lux_avg:.1f}")
            print(f"  Mass market brands: {mas_avg:.1f}")
            print(f"  Difference: {difference:+.1f} ({significance})")

        return image_analysis

    def analyze_trust_efficiency(self):
        print("\n【Trust Building Efficiency Comparison】")
        print("Trust Building Efficiency per Brand (Trust Index / Price per 100 yuan):")

        efficiency = {}
        for b, v in self.brand_data.items():
            price = v.get('price', 0) or 1e-9  # avoid division by zero
            eff = (v.get('trust_index', 0.0) / price) * 100.0
            efficiency[b] = eff
            print(f"{b} ({v.get('type','')}): {eff:.2f}")

        lux_e = [efficiency[b] for b in self.luxury_brands if b in efficiency]
        mas_e = [efficiency[b] for b in self.mass_brands if b in efficiency]
        lux_avg = np.mean(lux_e) if lux_e else 0.0
        mas_avg = np.mean(mas_e) if mas_e else 0.0

        print(f"\nEfficiency Comparison Results:")
        print(f"Luxury brands average efficiency: {lux_avg:.2f}")
        print(f"Mass market brands average efficiency: {mas_avg:.2f}")
        if lux_avg > 0:
            print(f"Mass market efficiency advantage: {(mas_avg / lux_avg):.1f}x")
        else:
            print("Mass market efficiency advantage: N/A")

        return efficiency

    def analyze_success_vs_failure_cases(self):
        print("\n【Success Model vs Failure Model Comparison】")
        # sort by trust_index
        sorted_brands = sorted(self.brand_data.items(), key=lambda x: x[1].get('trust_index', 0.0), reverse=True)
        if not sorted_brands:
            print("No brand data.")
            return

        top_brand, top_vals = sorted_brands[0]
        bottom_brand, bottom_vals = sorted_brands[-1]

        print("Most Successful Case Analysis:")
        print(f"{top_brand}: {top_vals.get('trust_index',0.0)}% trust index")
        # use top-3 image drivers for this brand
        top_img = self.brand_image_data.get(top_brand, {})
        if top_img:
            top_drivers = _top_k_dims(top_img, 3)
            driver_str = ", ".join([f"{self.image_dimension_names.get(k,k)}={v}" for k,v in top_drivers])
            print(f"Success factors (top image drivers): {driver_str}")

        print(f"\nLeast Successful Case Analysis:")
        print(f"{bottom_brand}: {bottom_vals.get('trust_index',0.0)}% trust index")
        bottom_img = self.brand_image_data.get(bottom_brand, {})
        if bottom_img:
            # show weakest 3
            weak_dims = sorted(bottom_img.items(), key=lambda x: x[1])[:3]
            weak_str = ", ".join([f"{self.image_dimension_names.get(k,k)}={v}" for k,v in weak_dims])
            print(f"Weak factors (lowest image scores): {weak_str}")


    def generate_comprehensive_report(self):
        print("COMPREHENSIVE TRUST MECHANISM ANALYSIS REPORT")

        basic_comparison = self.analyze_basic_comparison()
        pathway_analysis = self.analyze_trust_building_pathways()
        image_analysis = self.analyze_brand_image_differences()
        efficiency_data = self.analyze_trust_efficiency()
        self.analyze_success_vs_failure_cases()

        return {
            'basic_comparison': basic_comparison,
            'pathway_analysis': pathway_analysis,
            'image_analysis': image_analysis,
            'efficiency_data': efficiency_data
        }

analyzer = TrustMechanismAnalyzer(df2, image_df, trust_results)
results = analyzer.generate_comprehensive_report()
# analyzer.export_analysis_results()
# analyzer.create_comparison_visualization()
